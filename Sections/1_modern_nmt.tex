\section{Modern Neural Machine Translation}

\subsection{Overview}
\begin{frame}{Overview}
	
	\begin{itemize}
		\item MT objective
		\item from SMT to NMT (attention?)
		\item sota models
			\begin{itemize}
				\item transformer
				\item transformer variations like Compressive Transformer, Reformer, etc.
			\end{itemize}
		\item has MT reached human parity? \cite{laubli_has_2018}). No, we need DLNMT.
		\item discourse phenomena, what are they?
		\item DLNMT objective
	\end{itemize}
	
	
\end{frame}

\begin{frame}{Overview}
	
	Note: context here is mostly used to indicate the sentences of a document that are not the one currently being translated (both source or target side)
	
	MT output is usually evaluated by \textbf{average translation quality} metrics such as BLUE \cite{papineni_bleu_2002} and METEOR \cite{banerjee_meteor_2005}. They are calculate at sentence level by on the base of the number of overlapping n-grams between the translation and the reference. The document-level score is simply an average of the sentence-level scores.
	
	
\end{frame}

%\begin{frame}{The Reinforcement Learning Framework}
%\begin{figure}[t]
%	\centering
%	\begin{tikzpicture}[node distance = 6em, auto, thick]
%		\onslide<1->{%
%			\node at (4, 0) (Environment) {\includegraphics[width=3cm]{Images/environment}};
%			\node at (4, 2) {\LARGE Environment};
%			\node at (4, -2) {\LARGE $\calP$};
%		}
%		
%		\onslide<2->{%
%			\node at (-4, 0) (Agent) {\includegraphics[width=3cm]{Images/agent}};
%			\node at (-4, 2) {\LARGE Agent};
%			\node at (-4, -2) {\LARGE $\pi$};
%		}
%		
%		\onslide<3-5>{%
%		\draw [->, line width=5pt, MyOrange, opacity=0.7] (Environment) to [bend right=35] (Agent);
%		\node at (0, 2.5) {\Large State $s_h$};
%		}
%		
%		\onslide<4|handout:0>{%
%		\node[draw=MyOrange, opacity=0.7, circle, line width=3pt, minimum size=1cm] at (-4, -2) {};
%		}
%		
%		\onslide<5->{%
%		\draw [->, line width=5pt, MyOrange, opacity=0.7] (Agent) to [bend right=35] (Environment);
%		\node at (0, -2.5) {\Large Action $a_h$};
%		}
%		
%		\onslide<6|handout:0>{%
%		\node[draw=MyOrange, opacity=0.7, circle, line width=3pt, minimum size=1cm] at (4, -2) {};	
%		}
%
%		\onslide<6->{%
%		\draw [->, line width=5pt, MyOrange, opacity=0.7] (Environment) to [bend right=35] (Agent);
%		\node at (0, 2.5) {\Large State $s_{h+1}$};
%		}
%		
%%		\onslide<8|handout:0>{%
%%		\node[draw=MyOrange, opacity=0.7, circle, line width=3pt, minimum size=1cm] at (4.42, -2) {};	
%%		}
%					
%		\onslide<7->{%
%		\draw [->, line width=5pt, MyOrange, opacity=0.7] (Environment) to (Agent);
%		\node at (0, 0.5) {\Large Reward $r_{h+1}$};
%		}		
%	\end{tikzpicture}
%\end{figure}
%\end{frame}
%
%\subsection{Policy Search Formulation}
%\label{sec:policy_search_formulation}
%
%\begin{frame}{Policy Search Formulation}
%
%	\onslide<1->{%
%	\textbf{Parametric policy:}
%		\begin{equation*}
%		\pi_{\vtheta}:\Sspace\to\Delta(\Aspace) \qquad \text{ E.g.: } \pi_{\vtheta}(a|s) = \frac{1}{\sqrt{2\pi}\sigma}\exp\left(-\frac{1}{2}\left(\frac{a-\vtheta^Ts}{\sigma}\right)^2\right)
%		\end{equation*}
%	}
%
%	\onslide<2->{%
%	\textbf{Return of a trajectory $\tau$:}
%		\begin{equation*}
%		\Rew(\tau) = \sum_{h=0}^{H-1}\gamma^hr_{h+1},\text{ with } \tau=[s_0,a_0,s_1,a_1,\dots,s_{H-1},a_{H-1},s_H]
%		\end{equation*}
%	}
%	
%	
%	\onslide<3->{%
%	\textbf{Performance:}
%		\begin{equation*}
%		\mu(\vtheta) = \Exp_{\tau\sim \pi_{\vtheta}}[\Rew(\tau)]
%		\end{equation*}
%	}
%	
%	\onslide<4->{%
%	\textbf{Objective:}
%		\begin{equation*}
%\vtheta^* = \arg \max_{\vtheta\in\Theta}\mu(\vtheta).
%\end{equation*}
%	}
%	
%\end{frame}

%\begin{frame}{Taxonomy of RL Algorithms}
%\begin{figure}[t]
%	\centering
%	\begin{tikzpicture}[node distance = 6em, auto, thick]
%		
%		\onslide<1->{%
%			\node [draw=LightSteelBlue, circle, line width=5pt, minimum size=2cm] at (-4, 0) (Model) {\Large $\calP$, $\calR$};
%			\node at (-4, 1.5) {\Large Model};
%		}
%		
%		\onslide<2->{%
%			\node [draw=SteelBlue, circle, line width=5pt, minimum size=2cm] at (-0, 0) (Value) {\Large $V_*$, $Q_*$};
%			\node at (0, 1.5) {\Large Value Functions};
%			\draw [->, line width=5pt, LightGray] (Model) to (Value);
%		}
%
%		\onslide<3->{%
%			\node [draw=Blue, circle, line width=5pt, minimum size=2cm] at (4, 0) (Policy) {\Large $\pi_*$};
%			\node at (4, 1.5) {\Large Policy};
%			\draw [->, line width=5pt, LightGray] (Value) to (Policy);
%		}
%		
%		\onslide<4->{%
%			\node [draw=LightSteelBlue, circle, line width=5pt, minimum size=2cm] at (-4, -3) (ApproxModel) {\Large $\widehat{\calP}$, $\widehat{\calR}$};
%			\node at (-4, -4.5) {\Large Model-Based};
%			\draw [dashed, line width=5pt, LightGray] (ApproxModel) to (Model);
%		}
%		
%		\onslide<5->{%
%			\node [draw=SteelBlue, circle, line width=5pt, minimum size=2cm] at (0, -3) (ApproxValue) {\Large $\widehat{V}$, $\widehat{Q}$};
%			\node at (0, -4.5) {\Large Value-Based};
%			\draw [dashed, line width=5pt, LightGray] (ApproxValue) to (Value);
%		}
%		
%		\onslide<6->{%
%			\node [draw=Blue, circle, line width=5pt, minimum size=2cm] at (4, -3) (ApproxPolicy) {\Large $\widehat{\pi}$};
%			\node at (4, -4.5) {\Large Policy-Based};
%			\draw [dashed, line width=5pt, LightGray] (ApproxPolicy) to (Policy);
%		}
%	\end{tikzpicture}
%\end{figure}
%\end{frame}
%
%
%
%
